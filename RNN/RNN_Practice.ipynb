{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Practice.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abialbon/pytorch-udacity-scholarship/blob/master/RNN/RNN_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "28Udf3ySUOpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "63b693e1-ca45-4ceb-acb5-8b902ba7b0b9"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x58808000 @  0x7f0fbbd9c2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gCbMUge1Vg6n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "metadata": {
        "id": "guT8AdxvVl8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38f4250c-59e5-4b04-bd02-8b4b258d800d"
      },
      "cell_type": "code",
      "source": [
        "with open('text.txt', 'r') as f:\n",
        "    data = f.read()\n",
        "    tokens = set(data)\n",
        "    print('The length of the dataset is {} characters'.format(len(data)))\n",
        "    print('The number of unique chars is: {}'.format(len(tokens)))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the dataset is 94217 characters\n",
            "The number of unique chars is: 87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-JIBH3vDWX5z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebb4a17f-0b88-4692-f13d-1118e234ee46"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device == 'cuda':\n",
        "    print('Thank you Google Colab! Training on GPU!')"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thank you Google Colab! Training on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9G7F5ijtWpLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating a CharRNN\n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, tokens, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.tokens = tokens\n",
        "        self.hidden = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.n_tokens = len(self.tokens)\n",
        "        self.char2int = {ch:i for i, ch in enumerate(self.tokens)}\n",
        "        self.int2har = {i:ch for ch, i in self.char2int.items()}\n",
        "        \n",
        "        #Layers\n",
        "        self.lstm = nn.LSTM(input_size=self.n_tokens, hidden_size=self.hidden, num_layers=self.num_layers, dropout=0.5, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 32)\n",
        "        self.fc3 = nn.Linear(32, self.n_tokens)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        x, h = self.lstm(x)\n",
        "        x = x.contiguous().view(-1, self.hidden)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x, h\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weights = next(self.parameters()).data\n",
        "        return (torch.tensor(weights.new(self.num_layers, batch_size, self.hidden).zero_().to(device)),\n",
        "               torch.tensor(weights.new(self.num_layers, batch_size, self.hidden).zero_()).to(device))\n",
        "    \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3i2Q-EKilIv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "05a6d6be-bdb7-4b14-a469-e4add2aa7bf3"
      },
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "n_hidden = 512\n",
        "n_layers = 2\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 128\n",
        "seq_lenght = 100\n",
        "epochs = 20\n",
        "\n",
        "net = CharRNN(tokens, n_hidden, n_layers)\n",
        "net.to(device)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharRNN(\n",
              "  (lstm): LSTM(87, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
              "  (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "  (fc3): Linear(in_features=32, out_features=87, bias=True)\n",
              "  (dropout): Dropout(p=0.2)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "metadata": {
        "id": "myDEQOL0mH2W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batches(arr, b_s, s_l):\n",
        "    arr = arr.flatten()\n",
        "    n_b = len(data)//(b_s * s_l)\n",
        "    arr = arr[:n_b*b_s*s_l]\n",
        "    arr = arr.reshape(b_s, -1)\n",
        "    \n",
        "    for step in range(n_b):\n",
        "        x = arr[:, step*s_l : (step+1) * s_l]\n",
        "        y = np.zeros_like(x)\n",
        "        try:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, (step+1) * s_l]\n",
        "        except:\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
        "        yield x, y\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MzmwQaUjuK3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    l = np.multiply(*arr.shape)\n",
        "    z = np.zeros((l, n_labels))\n",
        "    z[np.arange(l), arr.flatten().astype('int')] = 1\n",
        "    z = z.reshape(*arr.shape, n_labels)\n",
        "    return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HaQPreAglDZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7ee638ff-e326-4173-8cef-113b91c03213"
      },
      "cell_type": "code",
      "source": [
        "def train(model, data, n_epochs=5, batch_size=128, seq_length=100, lr=0.01):\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    encoded_data = np.array([model.char2int[i] for i in data])\n",
        "    \n",
        "    for e in range(n_epochs):\n",
        "        h = model.init_hidden(batch_size)\n",
        "        train_loss = 0\n",
        "        counter = 0\n",
        "        \n",
        "        for x, y in get_batches(encoded_data, batch_size, seq_length):\n",
        "            counter += 1\n",
        "            x = torch.Tensor(one_hot_encode(x, model.n_tokens)).to(device)\n",
        "            y = torch.Tensor(y).type(torch.LongTensor).to(device)\n",
        "            output, h = model.forward(x, h)\n",
        "            \n",
        "            h = tuple([each.data for each in h])\n",
        "            loss = criterion(output, y.view(-1))\n",
        "            train_loss += loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), 5)\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            print('Loss: {:.3f}'.format(train_loss/counter))  \n",
        "      \n",
        "          \n",
        "\n",
        "train(net, data, 5, 20, 100, 0.01)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 3.159\n",
            "Loss: 2.818\n",
            "Loss: 2.592\n",
            "Loss: 2.447\n",
            "Loss: 2.343\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}